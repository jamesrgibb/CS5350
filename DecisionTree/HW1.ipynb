{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T13:24:34.692354Z",
     "start_time": "2023-10-16T13:23:55.591498Z"
    }
   },
   "id": "b687797fe037db88"
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "outputs": [],
   "source": [
    "column_names = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"label\"]\n",
    "train_data = pd.read_csv('car-4/train.csv',names=column_names)\n",
    "test_data = pd.read_csv('car-4/test.csv',names=column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:26.082630Z",
     "start_time": "2023-09-22T22:24:26.057812Z"
    }
   },
   "id": "c83269aeb166674b"
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "outputs": [
    {
     "data": {
      "text/plain": "  buying  maint  doors persons lug_boot safety  label\n0    low  vhigh      4       4      big    med    acc\n1    low   high  5more       4      med   high  vgood\n2  vhigh    med      2       2      big   high  unacc\n3   high   high      2       2    small   high  unacc\n4  vhigh    low      3       2      big    low  unacc",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>buying</th>\n      <th>maint</th>\n      <th>doors</th>\n      <th>persons</th>\n      <th>lug_boot</th>\n      <th>safety</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>low</td>\n      <td>vhigh</td>\n      <td>4</td>\n      <td>4</td>\n      <td>big</td>\n      <td>med</td>\n      <td>acc</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>low</td>\n      <td>high</td>\n      <td>5more</td>\n      <td>4</td>\n      <td>med</td>\n      <td>high</td>\n      <td>vgood</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>vhigh</td>\n      <td>med</td>\n      <td>2</td>\n      <td>2</td>\n      <td>big</td>\n      <td>high</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>high</td>\n      <td>high</td>\n      <td>2</td>\n      <td>2</td>\n      <td>small</td>\n      <td>high</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>vhigh</td>\n      <td>low</td>\n      <td>3</td>\n      <td>2</td>\n      <td>big</td>\n      <td>low</td>\n      <td>unacc</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:26.097623Z",
     "start_time": "2023-09-22T22:24:26.066860Z"
    }
   },
   "id": "badb6f7f721a79da"
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "outputs": [],
   "source": [
    "# Define the entropy\n",
    "def entropy(target_col):\n",
    "    value_counts = target_col.value_counts(normalize=True)\n",
    "    temp_entropy = -np.sum(value_counts * np.log2(value_counts))\n",
    "    return temp_entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:26.098073Z",
     "start_time": "2023-09-22T22:24:26.069811Z"
    }
   },
   "id": "96eb4f2352a4dee"
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "outputs": [],
   "source": [
    "# Define the majority error\n",
    "def majority_error(target_col):\n",
    "    value_counts = target_col.value_counts(normalize=True)\n",
    "    return 1 - np.max(value_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:26.098141Z",
     "start_time": "2023-09-22T22:24:26.074422Z"
    }
   },
   "id": "679d2bee174ed8e2"
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "outputs": [],
   "source": [
    "# Define the gini index\n",
    "def gini_index(target_col):\n",
    "    counts = target_col.value_counts()\n",
    "    probabilities = counts / len(target_col)\n",
    "    return 1 - np.sum(probabilities**2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:26.098370Z",
     "start_time": "2023-09-22T22:24:26.077003Z"
    }
   },
   "id": "9605701192a10bd4"
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "outputs": [],
   "source": [
    "def info_gain(data, split_attribute_name, target_name, criterion=\"entropy\"):\n",
    "    criterion_map = {\n",
    "        \"entropy\": entropy,\n",
    "        \"majority_error\": majority_error,\n",
    "        \"gini_index\": gini_index\n",
    "    }\n",
    "    if criterion not in criterion_map:\n",
    "        raise ValueError(\"Invalid criterion provided\")\n",
    "\n",
    "    total_impurity = criterion_map[criterion](data[target_name])\n",
    "\n",
    "    weighted_impurity = 0\n",
    "    for value, group in data.groupby(split_attribute_name):\n",
    "        weighted_impurity += (len(group) / len(data)) * criterion_map[criterion](group[target_name])\n",
    "\n",
    "    return total_impurity - weighted_impurity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:26.098705Z",
     "start_time": "2023-09-22T22:24:26.080527Z"
    }
   },
   "id": "b228779958204e57"
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "outputs": [],
   "source": [
    "def get_majority_class(data, target_attribute_name):\n",
    "    return data[target_attribute_name].value_counts().idxmax()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:26.099955Z",
     "start_time": "2023-09-22T22:24:26.083136Z"
    }
   },
   "id": "ab7218b9ee9a4aac"
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "outputs": [],
   "source": [
    "def ID3(data, original_data, features, target_attribute_name=\"label\", parent_node_class=None,\n",
    "        max_depth=None, depth=0, criterion=\"entropy\"):\n",
    "    unique_targets = np.unique(data[target_attribute_name])\n",
    "    if len(unique_targets) == 1:\n",
    "        return unique_targets[0]\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        return get_majority_class(original_data, target_attribute_name)\n",
    "\n",
    "    if len(features) == 0 or (max_depth and depth == max_depth):\n",
    "        return parent_node_class\n",
    "    \n",
    "    parent_node_class = get_majority_class(data, target_attribute_name)\n",
    "    \n",
    "    gains = [info_gain(data, feature, target_attribute_name, criterion) for feature in features]\n",
    "    best_feature = features[np.argmax(gains)]\n",
    "    tree = {best_feature: {}}\n",
    "\n",
    "    for value in np.unique(data[best_feature]):\n",
    "        best_val = data[best_feature] == value\n",
    "        sub_data = data.where(best_val).dropna()\n",
    "        remaining_features = [feat for feat in features if feat != best_feature]\n",
    "        subtree = ID3(\n",
    "            data=sub_data,\n",
    "            original_data=original_data,\n",
    "            features=remaining_features,\n",
    "            target_attribute_name=target_attribute_name,\n",
    "            parent_node_class=parent_node_class,\n",
    "            max_depth=max_depth,\n",
    "            depth=depth + 1,\n",
    "            criterion=criterion\n",
    "        )\n",
    "\n",
    "        tree[best_feature][value] = subtree\n",
    "\n",
    "    return tree"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:26.115588Z",
     "start_time": "2023-09-22T22:24:26.088418Z"
    }
   },
   "id": "f9df5483556b4f83"
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [
    "def predict(query, tree, default=1):\n",
    "    current_layer = tree\n",
    "    while isinstance(current_layer, dict):\n",
    "        key = next(iter(current_layer))\n",
    "        value = query.get(key)\n",
    "        if value is not None:\n",
    "            current_layer = current_layer[key].get(value, default)\n",
    "        else:\n",
    "            return default\n",
    "    return current_layer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:26.125044Z",
     "start_time": "2023-09-22T22:24:26.091199Z"
    }
   },
   "id": "cd78f56310719361"
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "outputs": [],
   "source": [
    "# Function to compute accuracy using lists\n",
    "def test(data, tree, target):\n",
    "    queries = data.drop(target, axis=1).to_dict(orient=\"records\")\n",
    "    predicted_values = [predict(query, tree) for query in queries]\n",
    "    correct_predictions = sum(1 for actual, predicted in zip(data[target], predicted_values) if actual == predicted)\n",
    "    return (correct_predictions / len(data)) * 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:26.125129Z",
     "start_time": "2023-09-22T22:24:26.094335Z"
    }
   },
   "id": "20d2d3a9f9b01f25"
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "outputs": [],
   "source": [
    "# Function to compute error\n",
    "def compute_error(tree, train_data, test_data, target):\n",
    "    train_accuracy = test(train_data, tree, target)\n",
    "    test_accuracy = test(test_data, tree, target)\n",
    "    return 100 - train_accuracy, 100 - test_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:26.125458Z",
     "start_time": "2023-09-22T22:24:26.096828Z"
    }
   },
   "id": "2707ac160402df00"
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Training Error  Test Error\n",
      "Criterion                                 \n",
      "entropy              16.500000   20.032051\n",
      "gini_index           16.616667   19.963370\n",
      "majority_error       17.433333   21.932234\n"
     ]
    }
   ],
   "source": [
    "columns = [\"Criterion\", \"Depth\", \"Training Error\", \"Test Error\"]\n",
    "\n",
    "# Create an empty DataFrame with the defined columns\n",
    "results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "criterions = [\"entropy\", \"majority_error\", \"gini_index\"]\n",
    "max_depths = list(range(1, 7))\n",
    "\n",
    "for criterion in criterions:\n",
    "    for max_depth in max_depths:\n",
    "        tree = ID3(train_data, train_data, list(train_data.columns[:-1]), max_depth=max_depth, criterion=criterion)\n",
    "        train_error, test_error = compute_error(tree, train_data, test_data, \"label\")\n",
    "\n",
    "        # Append the results directly to the DataFrame\n",
    "        results_df = results_df.append({\n",
    "            \"Criterion\": criterion,\n",
    "            \"Depth\": max_depth,\n",
    "            \"Training Error\": train_error,\n",
    "            \"Test Error\": test_error\n",
    "        }, ignore_index=True)\n",
    "\n",
    "average_errors = results_df.groupby('Criterion').mean()[['Training Error', 'Test Error']]\n",
    "print(average_errors)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:30.153043Z",
     "start_time": "2023-09-22T22:24:26.102438Z"
    }
   },
   "id": "ef96a95c75af5b01"
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "outputs": [
    {
     "data": {
      "text/plain": "   age          job  marital  education default  balance housing loan  \\\n0   41     services  married  secondary      no        0     yes   no   \n1   48  blue-collar   single  secondary      no      312     yes  yes   \n2   55   technician  married  secondary      no     1938      no  yes   \n3   54       admin.  married   tertiary      no       59     yes   no   \n4   34   management   single   tertiary      no     2646      no   no   \n\n    contact  day_of_week month  duration  campaign  pdays  previous poutcome  \\\n0   unknown            5   may       114         2     -1         0  unknown   \n1  cellular            3   feb       369         2     -1         0  unknown   \n2  cellular           18   aug       193         1    386         3  success   \n3  cellular           10   jul       268         1     -1         0  unknown   \n4  cellular           14   apr       142         1     -1         0  unknown   \n\n     y  \n0   no  \n1   no  \n2  yes  \n3   no  \n4  yes  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day_of_week</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>services</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>114</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>48</td>\n      <td>blue-collar</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>312</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>3</td>\n      <td>feb</td>\n      <td>369</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>1938</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>18</td>\n      <td>aug</td>\n      <td>193</td>\n      <td>1</td>\n      <td>386</td>\n      <td>3</td>\n      <td>success</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>59</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>10</td>\n      <td>jul</td>\n      <td>268</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34</td>\n      <td>management</td>\n      <td>single</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>2646</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>14</td>\n      <td>apr</td>\n      <td>142</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3\n",
    "columns = [\"age\", \"job\", \"marital\", \"education\", \"default\", \"balance\", \"housing\", \"loan\", \"contact\", \"day_of_week\", \"month\", \"duration\", \"campaign\", \"pdays\", \"previous\", \"poutcome\", \"y\"]\n",
    "\n",
    "train_data = pd.read_csv('bank-4/train.csv', names=columns, header=None)\n",
    "test_data = pd.read_csv('bank-4/test.csv', names=columns, header=None)\n",
    "train_missing_data = pd.read_csv('bank-4/train.csv', names=columns, header=None)\n",
    "test_missing_data = pd.read_csv('bank-4/test.csv', names=columns, header=None)\n",
    "\n",
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:30.189125Z",
     "start_time": "2023-09-22T22:24:30.154064Z"
    }
   },
   "id": "c6f043ade9b75aa3"
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "outputs": [
    {
     "data": {
      "text/plain": "   age           job  marital  education default  balance housing loan  \\\n0   41    management   single  secondary      no      764      no   no   \n1   39   blue-collar  married  secondary      no       49     yes   no   \n2   60       retired  married    primary      no        0      no   no   \n3   31  entrepreneur   single   tertiary      no      247     yes  yes   \n4   26       student   single    unknown      no     2020      no   no   \n\n     contact  day_of_week month  duration  campaign  pdays  previous poutcome  \\\n0   cellular           12   jun       230         2     -1         0  unknown   \n1   cellular           14   may       566         1    370         2  failure   \n2  telephone           30   jul       130         3     -1         0  unknown   \n3    unknown            2   jun       273         1     -1         0  unknown   \n4  telephone           28   jan        42         3     -1         0  unknown   \n\n    y  \n0  no  \n1  no  \n2  no  \n3  no  \n4  no  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day_of_week</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>management</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>764</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>12</td>\n      <td>jun</td>\n      <td>230</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>49</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>14</td>\n      <td>may</td>\n      <td>566</td>\n      <td>1</td>\n      <td>370</td>\n      <td>2</td>\n      <td>failure</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>retired</td>\n      <td>married</td>\n      <td>primary</td>\n      <td>no</td>\n      <td>0</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>30</td>\n      <td>jul</td>\n      <td>130</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31</td>\n      <td>entrepreneur</td>\n      <td>single</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>247</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>unknown</td>\n      <td>2</td>\n      <td>jun</td>\n      <td>273</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26</td>\n      <td>student</td>\n      <td>single</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>2020</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>28</td>\n      <td>jan</td>\n      <td>42</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:30.193011Z",
     "start_time": "2023-09-22T22:24:30.191023Z"
    }
   },
   "id": "8f66c86eb9769573"
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "outputs": [],
   "source": [
    "def ID3_numeric(data, original_data, features, target_attribute_name=\"y\", parent_node_class=None,\n",
    "        max_depth=None, depth=0, criterion=\"entropy\"):\n",
    "    unique_targets = np.unique(data[target_attribute_name])\n",
    "    if len(unique_targets) == 1:\n",
    "        return unique_targets[0]\n",
    "\n",
    "    if len(data) == 0:\n",
    "        return get_majority_class(original_data, target_attribute_name)\n",
    "\n",
    "    if len(features) == 0 or (max_depth and depth == max_depth):\n",
    "        return parent_node_class\n",
    "\n",
    "    parent_node_class = get_majority_class(data, target_attribute_name)\n",
    "\n",
    "    gains = [info_gain(data, feature, target_attribute_name, criterion) for feature in features]\n",
    "    best_feature = features[np.argmax(gains)]\n",
    "    tree = {best_feature: {}}\n",
    "\n",
    "    for value in np.unique(data[best_feature]):\n",
    "        best_val = data[best_feature] == value\n",
    "        sub_data = data.where(best_val).dropna()\n",
    "        remaining_features = [feat for feat in features if feat != best_feature]\n",
    "        subtree = ID3(\n",
    "            data=sub_data,\n",
    "            original_data=original_data,\n",
    "            features=remaining_features,\n",
    "            target_attribute_name=target_attribute_name,\n",
    "            parent_node_class=parent_node_class,\n",
    "            max_depth=max_depth,\n",
    "            depth=depth + 1,\n",
    "            criterion=criterion\n",
    "        )\n",
    "\n",
    "        tree[best_feature][value] = subtree\n",
    "\n",
    "    return tree"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:24:30.198277Z",
     "start_time": "2023-09-22T22:24:30.195717Z"
    }
   },
   "id": "2f8a57a763b256e5"
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Training Error  Test Error\n",
      "Criterion                                 \n",
      "entropy                 4.5950    16.30500\n",
      "gini_index              4.4100    17.14375\n",
      "majority_error          5.7975    16.81000\n"
     ]
    }
   ],
   "source": [
    "max_depths = list(range(1, 17))\n",
    "criterions = [\"entropy\", \"majority_error\", \"gini_index\"]\n",
    "# Converting string values to numbers for computing the median and then categorizing based on the median\n",
    "variables = [\"age\", \"balance\", \"day_of_week\", \"duration\", \"campaign\", \"previous\", \"pdays\"]\n",
    "train_data_copy = train_data.copy()\n",
    "\n",
    "for variable in variables:\n",
    "    median = train_data_copy[variable].median()\n",
    "    train_data[variable] = np.where(train_data[variable] >= median, \"high\", \"low\")\n",
    "    test_data[variable] = np.where(test_data[variable] >= median, \"high\", \"low\")\n",
    "\n",
    "results_df = pd.DataFrame(columns=columns)\n",
    "for criterion in criterions:\n",
    "    for max_depth in max_depths:\n",
    "        tree = ID3_numeric(train_data, train_data, list(train_data.columns[:-1]), max_depth=max_depth, criterion=criterion)\n",
    "        train_error, test_error = compute_error(tree, train_data, test_data, \"y\")\n",
    "\n",
    "        results_df = results_df.append({\n",
    "            \"Criterion\": criterion,\n",
    "            \"Depth\": max_depth,\n",
    "            \"Training Error\": train_error,\n",
    "            \"Test Error\": test_error\n",
    "        }, ignore_index=True)\n",
    "\n",
    "average_errors = results_df.groupby('Criterion').mean()[['Training Error', 'Test Error']]\n",
    "print(average_errors)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:29:14.436939Z",
     "start_time": "2023-09-22T22:24:30.201497Z"
    }
   },
   "id": "c3af1a6ca4b86e75"
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Training Error  Test Error\n",
      "Criterion                                 \n",
      "entropy               4.955625   36.976875\n",
      "gini_index            4.816875   51.901875\n",
      "majority_error        6.121250   51.668125\n"
     ]
    }
   ],
   "source": [
    "unknown_columns = [\"job\", \"education\", \"contact\", \"poutcome\"]\n",
    "test_missing_data = test_missing_data.copy()\n",
    "train_missing_data = train_missing_data.copy()\n",
    "for cat in unknown_columns:\n",
    "    majority_value = train_missing_data[train_missing_data[cat]!=\"unknown\"][cat].mode()[0]\n",
    "    train_missing_data[cat] = train_missing_data[cat].replace(\"unknown\", majority_value)\n",
    "for variable in variables:\n",
    "    median = train_missing_data[variable].median()\n",
    "    train_missing_data[variable] = np.where(train_missing_data[variable] >= median, \"high\", \"low\")\n",
    "    test_missing_data[variable] = np.where(test_missing_data[variable] >= median, \"high\", \"low\")\n",
    "    \n",
    "results = []\n",
    "for criterion in criterions:\n",
    "    for max_depth in max_depths:\n",
    "        tree = ID3_numeric(train_missing_data, train_missing_data, train_missing_data.columns[:-1],  max_depth=max_depth, criterion=criterion)\n",
    "        train_error, test_error = compute_error(tree, train_missing_data, test_missing_data, \"y\")\n",
    "        results.append((criterion, max_depth, train_error, test_error))\n",
    "\n",
    "        results_df = results_df.append({\n",
    "            \"Criterion\": criterion,\n",
    "            \"Depth\": max_depth,\n",
    "            \"Training Error\": train_error,\n",
    "            \"Test Error\": test_error\n",
    "        }, ignore_index=True)\n",
    "\n",
    "average_errors = results_df.groupby('Criterion').mean()[['Training Error', 'Test Error']]\n",
    "print(average_errors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T22:36:40.911543Z",
     "start_time": "2023-09-22T22:31:58.354485Z"
    }
   },
   "id": "6ac76bb964d0164"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
